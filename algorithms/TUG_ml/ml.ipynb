{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>average_speed</th>\n",
       "      <th>average_stride_length</th>\n",
       "      <th>RIGHT_SHOULDER_std_dev</th>\n",
       "      <th>RIGHT_HIP_std_dev</th>\n",
       "      <th>RIGHT_KNEE_std_dev</th>\n",
       "      <th>RIGHT_ANKLE_std_dev</th>\n",
       "      <th>frailty_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TUG</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>121.141992</td>\n",
       "      <td>94.577187</td>\n",
       "      <td>82.282711</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>44.00000</td>\n",
       "      <td>74.510839</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TUG</td>\n",
       "      <td>17.851167</td>\n",
       "      <td>35.996692</td>\n",
       "      <td>32.583830</td>\n",
       "      <td>6.834731</td>\n",
       "      <td>15.222791</td>\n",
       "      <td>5.93483</td>\n",
       "      <td>10.495398</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test  elapsed_time  average_speed  average_stride_length  \\\n",
       "0  TUG      5.500000     121.141992              94.577187   \n",
       "1  TUG     17.851167      35.996692              32.583830   \n",
       "\n",
       "   RIGHT_SHOULDER_std_dev  RIGHT_HIP_std_dev  RIGHT_KNEE_std_dev  \\\n",
       "0               82.282711          41.000000            44.00000   \n",
       "1                6.834731          15.222791             5.93483   \n",
       "\n",
       "   RIGHT_ANKLE_std_dev  frailty_score  \n",
       "0            74.510839              1  \n",
       "1            10.495398            100  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv\n",
    "df = pd.read_csv('Updated_TUG_final_results.csv')\n",
    "\n",
    "# Data cleaning\n",
    "\n",
    "\n",
    "df = df[df.columns.drop(list(df.filter(regex='circular_mean')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='circular_std')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='mean_magnitude')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='LEFT')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='TOE')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='NOSE')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='distance_walked')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='Stand')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='Walk To')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='Turn')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='Walk Back')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='Sit')))]\n",
    "\n",
    "\n",
    "# feature engineering\n",
    "# average max angle\n",
    "# TODO: FEATURE ENGINEERING\n",
    "\n",
    "df = df.sort_values(by=['frailty_score'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define keypoints columns\n",
    "keypoints_columns = [\n",
    "    'RIGHT_SHOULDER_std_dev', 'RIGHT_HIP_std_dev', \n",
    "    'RIGHT_KNEE_std_dev', 'RIGHT_ANKLE_std_dev']\n",
    "\n",
    "\n",
    "# Artificially change some values to see the effect on the plot\n",
    "# df['LEFT_HIP_std_dev'].iloc[1]= df['LEFT_HIP_std_dev'].iloc[1] -6\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "def frailty_level(score):\n",
    "    if score == 1:\n",
    "        return 'Low'\n",
    "    elif score == 100:\n",
    "        return 'High'\n",
    "    else:\n",
    "        return 'Moderate'\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    plt.plot(keypoints_columns, row[keypoints_columns], label=f'{frailty_level(row[\"frailty_score\"])}')\n",
    "\n",
    "plt.xlabel('Keypoints')\n",
    "plt.ylabel('Standard Deviation of Motion Magnitudes')\n",
    "plt.title('Standard Deviation of Motion Magnitudes for Each Keypoint')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df contains the benchmarks for the lowest and highest frailty subjects\n",
    "lowest_frailty_benchmark = df.iloc[0]  # Use this for upper bounds (least frail)\n",
    "highest_frailty_benchmark = df.iloc[-1]  # Use this for lower bounds (most frail)\n",
    "\n",
    "# Generate 1000 samples of synthetic data with frailty scores from 1 to 100\n",
    "n_samples = 1000\n",
    "frailty_scores = np.round(np.linspace(1, 100, n_samples), 1)\n",
    "\n",
    "# List to store generated synthetic data\n",
    "synthetic_data = []\n",
    "\n",
    "# Generate synthetic data based on frailty score rules\n",
    "for score in frailty_scores:\n",
    "    # Rule: for scores > 50, total time > 12 seconds, scaled by frailty score\n",
    "    if score > 50:\n",
    "        total_time = np.random.uniform(12, highest_frailty_benchmark['time'])  # Time increases with frailty score\n",
    "    else:\n",
    "        total_time = np.random.uniform(lowest_frailty_benchmark['time'], 12)  # Faster times for lower scores\n",
    "    \n",
    "    # Max and Min Angles: Decrease with frailty score, bounded by benchmarks\n",
    "    max_max_angle = np.random.uniform(highest_frailty_benchmark['max_max_angle'], lowest_frailty_benchmark['max_max_angle'])\n",
    "    min_max_angle = np.random.uniform(highest_frailty_benchmark['min_max_angle'], lowest_frailty_benchmark['min_max_angle'])\n",
    "\n",
    "    # Joint movement variation: Decrease with frailty score, bounded by benchmarks\n",
    "    shoulder_std = np.random.uniform(highest_frailty_benchmark['LEFT_SHOULDER_std_dev'], lowest_frailty_benchmark['LEFT_SHOULDER_std_dev'])\n",
    "    hip_std = np.random.uniform(highest_frailty_benchmark['LEFT_HIP_std_dev'], lowest_frailty_benchmark['LEFT_HIP_std_dev'])\n",
    "    knee_std = np.random.uniform(highest_frailty_benchmark['LEFT_KNEE_std_dev'], lowest_frailty_benchmark['LEFT_KNEE_std_dev'])\n",
    "    ankle_std = np.random.uniform(highest_frailty_benchmark['NOSE_std_dev'], lowest_frailty_benchmark['NOSE_std_dev'])\n",
    "\n",
    "    # Append the generated data for this row\n",
    "    synthetic_data.append({\n",
    "        'time': total_time,\n",
    "        'max_max_angle': max_max_angle,\n",
    "        'min_max_angle': min_max_angle,\n",
    "        'RIGHT_SHOULDER_std_dev': shoulder_std,\n",
    "        'RIGHT_HIP_std_dev': hip_std,\n",
    "        'RIGHT_KNEE_std_dev': knee_std,\n",
    "        'RIGHT_ANKLE_std_dev': ankle_std,\n",
    "        'frailty_score': score\n",
    "    })\n",
    "\n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "# Convert the list of synthetic data to a DataFrame\n",
    "df_synthetic = pd.DataFrame(synthetic_data)\n",
    "df_synthetic['time'] = pd.to_numeric(df_synthetic['time'], errors='coerce')  # Convert to numeric, NaN for invalid parsing\n",
    "df_synthetic['avg_duration'] = df_synthetic['time'].apply(lambda x: x/5)\n",
    "# Save the synthetic data to a CSV file\n",
    "df_synthetic.to_csv('synthetic_data_sit_stand.csv', index=False)\n",
    "\n",
    "# Print the synthetic DataFrame\n",
    "print(df_synthetic.columns)\n",
    "\n",
    "# Plot the synthetic data for visualizing the relationship between frailty score and total time\n",
    "plt.scatter(df_synthetic['frailty_score'], df_synthetic['time'])\n",
    "plt.xlabel('Frailty Score (1 to 100)')\n",
    "plt.ylabel('Total Time (seconds)')\n",
    "plt.title('Total Time vs Frailty Score (1 to 100) - Sit Stand Test')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time', 'average_speed', 'RIGHT_SHOULDER_std_dev', 'RIGHT_HIP_std_dev',\n",
      "       'RIGHT_KNEE_std_dev', 'RIGHT_ANKLE_std_dev', 'shoulder_hip_ratio',\n",
      "       'knee_ankle_ratio', 'hip_knee_ratio', 'movement_stability'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        1.0\n",
       "1        1.1\n",
       "2        1.2\n",
       "3        1.3\n",
       "4        1.4\n",
       "       ...  \n",
       "995     99.6\n",
       "996     99.7\n",
       "997     99.8\n",
       "998     99.9\n",
       "999    100.0\n",
       "Name: frailty_score, Length: 1000, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "imported_syntethic_df = pd.read_csv('synthetic_data_sit_stand.csv')\n",
    "\n",
    "\n",
    "# Feature engineering\n",
    "imported_syntethic_df['shoulder_hip_ratio'] = imported_syntethic_df['RIGHT_SHOULDER_std_dev'] / imported_syntethic_df['RIGHT_HIP_std_dev']\n",
    "imported_syntethic_df['knee_ankle_ratio'] = imported_syntethic_df['RIGHT_KNEE_std_dev'] / imported_syntethic_df['RIGHT_ANKLE_std_dev']\n",
    "imported_syntethic_df['hip_knee_ratio'] = imported_syntethic_df['RIGHT_HIP_std_dev'] / imported_syntethic_df['RIGHT_KNEE_std_dev']\n",
    "imported_syntethic_df['movement_stability'] = (imported_syntethic_df['RIGHT_SHOULDER_std_dev'] + \n",
    "                                      imported_syntethic_df['RIGHT_HIP_std_dev'] + \n",
    "                                      imported_syntethic_df['RIGHT_KNEE_std_dev'] + \n",
    "                                      imported_syntethic_df['RIGHT_ANKLE_std_dev']) / 4\n",
    "\n",
    "\n",
    "X = imported_syntethic_df.drop(columns=['frailty_score'])\n",
    "print(X.columns)\n",
    "y = imported_syntethic_df['frailty_score']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X = imported_syntethic_df.drop(columns=['frailty_score'])  # All columns except frailty_score\n",
    "y = imported_syntethic_df['frailty_score']  # Target variable\n",
    "\n",
    "# Split the dataset into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2_score = lr_model.score(X_test, y_test)\n",
    "\n",
    "\n",
    "print(f'Mean Absolute Error: {mae:.2f}')\n",
    "print(f'Mean Squared Error: {mse:.2f}')\n",
    "print(f'R^2 Score: {r2_score:.2f}')\n",
    "\n",
    "# print(lr_model.predict(testing_input.drop(columns=['frailty_score']).values.reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor  # Importing Random Forest Regressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error \n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)  # You can adjust the number of trees (n_estimators)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rf_mae = mean_absolute_error(y_test, y_pred)\n",
    "rf_mse = mean_squared_error(y_test, y_pred)\n",
    "rf_r2score = rf_model.score(X_test, y_test)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Mean Absolute Error: {rf_mae:.2f}')\n",
    "print(f'Mean Squared Error: {rf_mse:.2f}')\n",
    "print(f'R^2 Score: {rf_r2score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required library for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the feature importances from the Random Forest model\n",
    "feature_importances = rf_model.feature_importances_\n",
    "\n",
    "# Get the feature names from the dataset\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create a DataFrame for the feature importances\n",
    "importances_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the feature importances in descending order\n",
    "importances_df = importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importances_df['Feature'], importances_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance from Random Forest')\n",
    "plt.gca().invert_yaxis()  # To display the most important features on top\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],        # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],       # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],       # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],         # Minimum number of samples required to be at a leaf node\n",
    "    'bootstrap': [True, False]             # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, \n",
    "                           cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Fit the grid search model to the training data (without weighting)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found by GridSearchCV\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "\n",
    "# Get the best estimator (model with the best parameters)\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set (without weighting)\n",
    "y_pred_best_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# Print predictions\n",
    "print(f\"y_pred_best_rf: {y_pred_best_rf}\")\n",
    "\n",
    "# Calculate performance metrics\n",
    "mae_best_rf = mean_absolute_error(y_test, y_pred_best_rf)\n",
    "mse_best_rf = mean_squared_error(y_test, y_pred_best_rf)\n",
    "\n",
    "print(f\"Best Random Forest Model MAE: {mae_best_rf:.2f}\")\n",
    "print(f\"Best Random Forest Model MSE: {mse_best_rf:.2f}\")\n",
    "print(f\"Best Random Forest Model R^2 Score: {best_rf_model.score(X_test, y_test):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "r2_score_xgb = xgb_model.score(X_test, y_test)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"XGBoost Model MAE: {mae_xgb:.2f}\")\n",
    "print(f\"XGBoost Model MSE: {mse_xgb:.2f}\")\n",
    "print(f\"XGBoost Model R^2 Score: {r2_score_xgb:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all scores for different models\n",
    "print(f\"Linear Regression Model MAE: {mae:.2f}\")\n",
    "print(f\"Linear Regression Model MSE: {mse:.2f}\")\n",
    "print(f\"Linear Regression Model R^2 Score: {r2_score:.2f}\")\n",
    "\n",
    "print(f\"Random Forest Model MAE: {rf_mae:.2f}\")\n",
    "print(f\"Random Forest Model MSE: {rf_mse:.2f}\")\n",
    "print(f\"Random Forest Model R^2 Score: {rf_r2score:.2f}\")\n",
    "\n",
    "print(f\"Best Random Forest Model MAE: {mae_best_rf:.2f}\")\n",
    "print(f\"Best Random Forest Model MSE: {mse_best_rf:.2f}\")\n",
    "print(f\"Best Random Forest Model R^2 Score: {best_rf_model.score(X_test, y_test):.2f}\")\n",
    "\n",
    "print(f\"XGBoost Model MAE: {mae_xgb:.2f}\")\n",
    "print(f\"XGBoost Model MSE: {mse_xgb:.2f}\")\n",
    "print(f\"XGBoost Model R^2 Score: {r2_score_xgb:.2f}\")\n",
    "\n",
    "\n",
    "# present in a table format\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Random Forest', 'Best Random Forest', 'XGBoost'],\n",
    "    'MAE': [mae, rf_mae, mae_best_rf, mae_xgb],\n",
    "    'MSE': [mse, rf_mse, mse_best_rf, mse_xgb],\n",
    "    'R^2 Score': [r2_score, rf_r2score, best_rf_model.score(X_test, y_test), r2_score_xgb]\n",
    "})\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# get current timestamp\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "# Save the best Random Forest model to a file\n",
    "joblib.dump(best_rf_model, f'TUG_rf_model_{now}.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
