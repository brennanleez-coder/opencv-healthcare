{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# key joints for a sit to stand\n",
    "# Hip joints: 23,24 (left, right hips)\n",
    "# Knee joints: 25,26 (left, right knees)\n",
    "# Ankle joints: 27,28 (left, right ankles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEFT_HIP 23\n",
      "RIGHT_HIP 24\n",
      "LEFT_KNEE 25\n",
      "RIGHT_KNEE 26\n",
      "LEFT_ANKLE 27\n",
      "RIGHT_ANKLE 28\n"
     ]
    }
   ],
   "source": [
    "for landmark in mp_pose.PoseLandmark:\n",
    "    if (landmark.name == \"LEFT_HIP\" or\n",
    "        landmark.name == \"RIGHT_HIP\" or\n",
    "        landmark.name == \"LEFT_KNEE\" or\n",
    "        landmark.name == \"RIGHT_KNEE\" or\n",
    "        landmark.name == \"LEFT_ANKLE\" or\n",
    "        landmark.name == \"RIGHT_ANKLE\"):\n",
    "        print(landmark.name, landmark.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b is the midpoint of a and c (e.g. left hip, left elbow and left shoulder)\n",
    "# our case will be left-hip, left-knee and left-ankle\n",
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "\n",
    "        \n",
    "    return angle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1716913113.575674 2358687 gl_context.cc:357] GL version: 2.1 (2.1 ATI-5.2.4), renderer: AMD Radeon Pro 5500M OpenGL Engine\n",
      "2024-05-29 00:18:33,763 - INFO - Frame captured and processing started.\n",
      "/Users/brennanlee/Desktop/opencv-healthcare/myenv/lib/python3.11/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "2024-05-29 00:18:33,966 - INFO - Calculated knee angle: 95.80258703686349\n",
      "2024-05-29 00:18:33,968 - INFO - Initial stage set to down.\n",
      "2024-05-29 00:18:34,064 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:34,154 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:34,240 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:34,317 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:34,397 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:34,475 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:34,551 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:34,627 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:34,702 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:34,778 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:34,855 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:34,930 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:35,003 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:35,079 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:35,155 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:35,230 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:35,305 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:35,381 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:35,455 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:35,530 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:35,604 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:35,677 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:35,756 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:35,832 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:35,906 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:35,980 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:36,053 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:36,127 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:36,201 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:36,274 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:36,347 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:36,421 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:36,495 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:36,569 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:36,645 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:36,721 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:36,793 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:36,868 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:36,941 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:37,014 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:37,090 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:37,166 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:37,240 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:37,315 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:37,390 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:37,464 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:37,541 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:37,616 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:37,690 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:37,764 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:37,838 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:37,911 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:37,988 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:38,063 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:38,138 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:38,213 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:38,287 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:38,374 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:38,456 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:38,531 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:38,604 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:38,678 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:38,753 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:38,826 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:38,901 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:38,976 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:39,059 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:39,134 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:39,210 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:39,283 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:39,357 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:39,432 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:39,506 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:39,580 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:39,655 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:39,728 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:39,802 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:39,879 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:39,954 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:40,028 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:40,103 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:40,176 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:40,251 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:40,327 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:40,401 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:40,477 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:40,553 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:40,626 - INFO - Frame captured and processing started.\n",
      "2024-05-29 00:18:40,703 - INFO - Frame captured and processing started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video ended\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Curl counter variables\n",
    "counter = 0\n",
    "stage = None\n",
    "frame_count = 0\n",
    "confirm_frames = 5\n",
    "stage_counter = 0\n",
    "\n",
    "# for storing the max angle achieved in a rep\n",
    "max_angle_per_rep = 0\n",
    "last_angle = 0\n",
    "\n",
    "# for optical flow postprocessing\n",
    "hip_history = []\n",
    "knee_history = []\n",
    "ankle_history = []\n",
    "\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    cap = cv2.VideoCapture(\"../test/CST_self2.mp4\")\n",
    "    while cap.isOpened():\n",
    "        # how to read from video\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            logging.warning(\"No frame captured from the video source.\")\n",
    "            break\n",
    "        logging.info(\"Frame captured and processing started.\")\n",
    "\n",
    "\n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            # Check if landmarks are detected\n",
    "            if not results.pose_landmarks:\n",
    "                logging.warning(\"No pose landmarks detected.\")\n",
    "                continue\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "            # Get coordinates\n",
    "            hip = [\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x * frame_width,\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y * frame_height,\n",
    "            ]\n",
    "            ankle = [\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x * frame_width,\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y * frame_height,\n",
    "            ]\n",
    "            knee = [\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x * frame_width,\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y * frame_height,\n",
    "            ]\n",
    "            hip_history.append(hip)\n",
    "            knee_history.append(knee)\n",
    "            ankle_history.append(ankle)\n",
    "            if len(hip_history) > 1:\n",
    "                hip_disp = calculate_distance(hip_history[-2], hip_history[-1])\n",
    "                knee_disp = calculate_distance(knee_history[-2], knee_history[-1])\n",
    "                ankle_disp = calculate_distance(ankle_history[-2], ankle_history[-1])\n",
    "                \n",
    "                hip_velocity = hip_disp / frame_time\n",
    "                knee_velocity = knee_disp / frame_time\n",
    "                ankle_velocity = ankle_disp / frame_time\n",
    "\n",
    "                logging.info(f\"Hip velocity: {hip_velocity:.2f}, Knee velocity: {knee_velocity:.2f}, Ankle velocity: {ankle_velocity:.2f}\")\n",
    "\n",
    "            # Calculate angle\n",
    "            angle = calculate_angle(hip, knee, ankle)\n",
    "            logging.info(f\"Calculated knee angle: {angle}\")\n",
    "            \n",
    "            # Offset position to display the angle beside the knee, offset by 60 pixels\n",
    "            knee_text_position = (int(knee[0] + 60), int(knee[1]))\n",
    "            cv2.putText(\n",
    "                image,\n",
    "                f\"{angle} deg\",\n",
    "                knee_text_position,\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (255, 255, 255),\n",
    "                2,\n",
    "                cv2.LINE_AA,\n",
    "            )\n",
    "\n",
    "            # Update max angle for the current rep\n",
    "            if angle > max_angle_per_rep:\n",
    "                max_angle_per_rep = angle\n",
    "\n",
    "            # Check if angle starts to decrease\n",
    "            if last_angle > angle:\n",
    "                max_angle_achieved = max_angle_per_rep\n",
    "            last_angle = angle\n",
    "\n",
    "            # CST counter logic\n",
    "            if stage is None:\n",
    "                # Determine the initial stage based on the first frame's angle\n",
    "                if angle > 135:\n",
    "                    stage = \"up\"\n",
    "                    logging.info(\"Initial stage set to up.\")\n",
    "\n",
    "                else:\n",
    "                    stage = \"down\"\n",
    "                    logging.info(\"Initial stage set to down.\")\n",
    "\n",
    "\n",
    "            if stage == \"down\" and angle > 135:\n",
    "                stage_counter += 1\n",
    "                if stage_counter >= confirm_frames:\n",
    "                    stage = \"up\" \n",
    "                    stage_counter = 0\n",
    "                    counter += 1  # Increment counter on transitioning to \"up\"\n",
    "                    logging.info(f\"Transitioned to up. Total reps: {counter}\")\n",
    "                    max_angle_per_rep = 0  # Reset max angle for the new repetition\n",
    "\n",
    "            elif stage == \"up\" and angle < 90:\n",
    "                stage_counter += 1\n",
    "                if stage_counter >= confirm_frames:\n",
    "                    stage = \"down\"\n",
    "                    stage_counter = 0  # Reset the stage counter after confirming the stage\n",
    "                    logging.info(\"Transitioned to down.\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Render curl counter\n",
    "        # Setup status box\n",
    "        cv2.rectangle(image, (0, 0), (225, 73), (245, 117, 16), -1)\n",
    "\n",
    "        # Rep data\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            \"REPS\",\n",
    "            (15, 12),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 0, 0),\n",
    "            1,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            str(counter),\n",
    "            (10, 60),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            2,\n",
    "            (255, 255, 255),\n",
    "            2,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "        # Stage data\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            \"STAGE\",\n",
    "            (65, 12),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 0, 0),\n",
    "            1,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            stage,\n",
    "            (60, 60),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            2,\n",
    "            (255, 255, 255),\n",
    "            2,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "            mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2),\n",
    "        )\n",
    "\n",
    "        cv2.imshow(\"Mediapipe Feed\", image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    print(\"video ended\")\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
